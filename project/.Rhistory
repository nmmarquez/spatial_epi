pivot_df$Teacher <- sapply(pivot_df$Class, function(x) strsplit(x, " ")[[1]][2])
pivot_df$School <- sapply(pivot_df$Class, function(x) strsplit(x, " ")[[1]][1])
# Load in the identifier data
id_vars <- c("PAWS.ID", "Cohort", "School", "Teacher", "Child.s.Name")
identity <- read.csv("~/Documents/PAWS/all_cohorts_info.csv",
stringsAsFactors=FALSE)[,id_vars]
identity$PAWS.ID <- as.numeric(gsub("\\.", "", identity$PAWS.ID))
identity$PAWSID <-  identity$PAWS.ID
identity$PAWS.ID <- NULL
adjust_name <- function(first_last){
first_last <- gsub("\\s*\\([^\\)]+\\)","",as.character(first_last))
name_vec <- strsplit(first_last, " ")[[1]]
if (length(name_vec) > 2){
name_vec <- c(name_vec[1], name_vec[length(name_vec)])
}
last_initial <- paste0(strsplit(name_vec[2], "")[[1]][1], ".")
return(paste(name_vec[1], last_initial))
}
identity$abrev_name <- sapply(identity$Child.s.Name, adjust_name)
identity$School <- sapply(identity$School, function(x) strsplit(x, " ")[[1]][1])
identity$Teacher <- sapply(identity$Teacher, function(x) strsplit(x, " |/|-")[[1]][1])
identity <- subset(identity, select=c(School,Teacher, PAWSID, abrev_name))
identity <- rename(identity, c("abrev_name"="subject"))
# merge PAWSID onto pivoted behavior data
pivot_df<- merge(pivot_df, identity, all.x=TRUE)
pivot_df$paws_student <- !is.na(pivot_df$PAWSID)
# look up each unique individual without an ID and assign them one
df_new_id <- unique(pivot_df[,c("subject", "Teacher", "School")])
row.names(df_new_id) <- NULL
df_new_id$PAWSID <- as.numeric(rownames(df_new_id))
df_new_id
pivot_df[is.na(pivot_df$PAWSID),"PAWSID"]
pivot_df[is.na(pivot_df$PAWSID),]
head(pivot_df[is.na(pivot_df$PAWSID),])
df_new_id <- unique(pivot_df[,c("subject", "Teacher", "School", "class")])
df_new_id <- unique(pivot_df[,c("subject", "Teacher", "School", "Class")])
row.names(df_new_id) <- NULL
df_new_id$PAWSID <- as.numeric(rownames(df_new_id))
merge(x = subset(pivot_df[is.na(pivot_df$PAWSID),]), select=-c(PAWSID),
y = df_new_id, by=c("Class", "Teacher", "School"), all.x=TRUE)
nrow(subset(pivot_df[is.na(pivot_df$PAWSID),]), select=-c(PAWSID))
nrow(subset(pivot_df[is.na(pivot_df$PAWSID),], select=-c(PAWSID))
)
merge(x = subset(pivot_df[is.na(pivot_df$PAWSID),], select=-c(PAWSID)),
y = df_new_id, by=c("Class", "Teacher", "School"), all.x=TRUE)
merge(x = subset(pivot_df[is.na(pivot_df$PAWSID),], select=-c(PAWSID)),
y = df_new_id, all.x=TRUE)
nrow(merge(x = subset(pivot_df[is.na(pivot_df$PAWSID),], select=-c(PAWSID)), y = df_new_id, all.x=TRUE)
)
nrow(subset(pivot_df[is.na(pivot_df$PAWSID),], select=-c(PAWSID)))
pivot_df[is.na(pivot_df$PAWSID),"PAWSID"] <-
merge(x = subset(pivot_df[is.na(pivot_df$PAWSID),], select=-c(PAWSID)),
y = df_new_id, all.x=TRUE)$PAWSID
pivot_df <- merge(x = pivot_df,
y = rename(unique(pivot_df[,c("PAWSID", "subject",
"Teacher", "School")]),
c(subject="partner", PAWSID="partnerID")),
by = c("partner", "Teacher", "School", "Class"), all.x = TRUE)
pivot_df <- merge(x = pivot_df,
y = rename(unique(pivot_df[,c("PAWSID", "subject", "Class",
"Teacher", "School")]),
c(subject="partner", PAWSID="partnerID")),
by = c("partner", "Teacher", "School", "Class"), all.x = TRUE)
# go back to the original format now that data ids are merged on
pivot_df_receive <- subset(pivot_df, role == "receiver")
recieve_transform <- c(subject="Code_R", PAWSID="PAWSID_R",
paws_student="paws_student_R")
pivot_df_receive <- rename(pivot_df_receive, recieve_transform)
pivot_df_receive <- subset(pivot_df_receive, select=-c(role, partnerID, partner))
pivot_df_send <- subset(pivot_df, role == "sender")
send_transform <- c(subject="Code_S", PAWSID="PAWSID_S",
paws_student="paws_student_S")
pivot_df_send <- rename(pivot_df_send, send_transform)
pivot_df_send <- subset(pivot_df_send, select=-c(role, partnerID, partner))
merged_interactions <- merge(pivot_df_send, pivot_df_receive)
source('~/Dropbox/PAWS-Neal/neal_analysis/data_reshape.R', echo=TRUE)
source('~/Dropbox/PAWS-Neal/neal_analysis/examine_network.R', echo=TRUE)
schools
source("ohio.dat")
source("~/Documents/Classes/spatial_epi/homework/hw1/ohio.dat")
ohio
summary(ohio)
ncounty <- 1
for (i in 1:ncounty){
indi <- (i-1)*16+seq(1,16)
Y[i] <- sum(ohio$deaths[indi])
}
Y <- NULL
ncounty <- 1
for (i in 1:ncounty){
indi <- (i-1)*16+seq(1,16)
Y[i] <- sum(ohio$deaths[indi])
}
indi
head(ohio)
table(ohio$fips)
length(unique(ohio$fips))
Y <- NULL
ncounty <- length(unique(ohio$fips))
for (i in 1:ncounty){
indi <- (i-1)*16+seq(1,16)
Y[i] <- sum(ohio$deaths[indi])
}
library(maps)
library(sp)
library(RColorBrewer)
plotvar <- Y # variable we want to map
nclr <- 8 # next few lines set up the color scheme for plotting
plotclr <- brewer.pal(nclr,"BuPu")
brks <- round(quantile(plotvar,probs=seq(0,1,1/(nclr))),digits=1)
colornum <- findInterval(plotvar,brks,all.inside=T)
colcode <- plotclr[colornum]
# Note order of data in file is in terms of increasing FIPS codes, which is the same
# as in the map function (see county.fips)
map("county", "ohio",col=colcode,fill=T)
title("Lung cancer deaths in Ohio in 1988")
leg.txt <- paste("[",brks[nclr],",",brks[nclr+1],"]",sep="")
for(i in (nclr-1):1){
leg.txt <- append(leg.txt,paste("[",brks[i],",",brks[i+1],")",sep=""),)
}
leg.txt <- rev(leg.txt)
legend("bottomright",legend=leg.txt,fill=plotclr,bty="n",cex=.8)
legend("topleft",legend=leg.txt,fill=plotclr,bty="n",cex=.8)
source('~/Documents/Classes/spatial_epi/homework/hw1/OhioScript-1.R', echo=TRUE)
source('~/Documents/Classes/spatial_epi/homework/hw1/OhioScript-1.R', echo=TRUE)
head(ohio)
source('~/Documents/Classes/spatial_epi/homework/hw1/OhioScript-1.R', echo=TRUE)
source('~/Documents/Classes/spatial_epi/homework/hw1/OhioScript-1.R', echo=TRUE)
for (s in unique(strata$sex)){
for (r in unique(strata$race)){
with(subset(strata, race == r & sex == s), plot(age, prob))
}
}
library(SpatialEpi)
library(inla)
library(INLABMA)
install.packages("INLA")
install.packages("INLA", repos="http://www.math.ntnu.no/inla/R/stable")
library(INLA)
Scotland
scotland
data("Scotland")
clas(Scotland)
class(Scotland)
data("scotland")
class(scotland)
head(Scotland)
table(Scotland$Region)
scotland.fit1X <- inla(Counts ~ 1 + I(X) + f(Region,
model = "iid", param = c(1, 0.014)), data = Scotland,
family = "poisson", E = E)
summary(scotland.fit1X)
install.packages()
install.packages("maxLik")
rbeta(1,1,1)
rbeta(1000,1,1)
hist(rbeta(1000,1,1))
hist(rbeta(1000,1,.3))
hist(rbeta(1000,3,.3))
hist(rbeta(1000,10,2))
hist(rbeta(1000,10,3))
hist(rbeta(1000,10,10))
plot(density(rbeta(1000,10,10)))
dbeta(.5,10,10)
?dbeta
dbeta(.5,10,10,log=TRUE)
dbeta(.6,10,10,log=TRUE)
dbeta(.4,10,10,log=TRUE)
dbeta(c(.4, .6, .5),10,10,log=TRUE)
rm(list=ls())
source("~/Documents/Classes/spatial_epi/homework/hw1/ohio.dat")
head(ohio)
library(SpatialEpi)
library(maps)
library(sp)
library(RColorBrewer)
?eBayes
library(plyr)
strata <- ddply(ohio, ~age+sex+race, summarise,
deaths=sum(deaths), popn=sum(popn))
source('~/Documents/Classes/spatial_epi/homework/hw2/hw2.R', echo=TRUE)
head(county)
?EBpostdens
?rgamma
is.null(3)
seq(0,1,.25)
library(INLA)
hist(rgamma(1000,5,5))
hist(rlnorm(1000,0,1))
mean(rlnorm(1000,0,1))
library(INLA)
?inla
?f
names(inla.models()$latent)
dgamma(2,10,5)
dgamma(200,10,5)
dgamma(20,10,5)
dgamma(.002,10,5)
dgamma(.2,10,5)
dgamma(.2,10,5,log=True)
dgamma(.2,10,5,log=T)
dgamma(2,10,5,log=T)
source('~/Dropbox/PAWS-Neal/neal_analysis/data_reshape.R', echo=TRUE)
source('~/Dropbox/PAWS-Neal/neal_analysis/examine_network.R', echo=TRUE)
library("foreign")
library("igraph")
library("plyr")
rm(list=ls())
getwd()
source("~/Dropbox/PAWS-Neal/neal_analysis/network_app/utilities.R")
data_sets <- load_data()
df <- data_sets[[1]]
df_status <- data_sets[[2]]
source("~/Dropbox/PAWS-Neal/neal_analysis/network_app/utilities.R")
sub_mat <- create_sub_matrix("prosocial", teacher=NULL, df, df_status)
dim(sub_mat)
sub_mat <- create_sub_matrix("prosocial", teacher=NULL, df, df_status)
g1 <- graph.adjacency(sub_mat)
V(g1)$color <- as.factor(df_status$paws_student)
#V(g1)$color=gsub("FALSE","red",V(g1)$color) #Females will be red
#V(g1)$color=gsub("TRUE","blue",V(g1)$color) #Males will be blue
plot(g1, layout=layout.fruchterman.reingold, vertex.label=NA,
vertex.size=8, edge.arrow.size=.25)
source('~/Dropbox/PAWS-Neal/neal_analysis/examine_network.R', echo=TRUE)
shiny::runApp('Documents/tmp/pac_app')
install.packages("devtools")
library("shinyapps")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='nmarquez',
token='9110009049F07B35E06BCA3977FCBB29',
secret='btaCQnln6280gV0v+kK9/gYya1u66HNRAG2CaUnz')
library("shinyapps")
deployApp("~/Documents/tmp/pac_app/")
source('~/Dropbox/PAWS-Neal/neal_analysis/data_reshape.R', echo=TRUE)
head(identity)
summary(identity$Teacher)
table(identity$Teacher)
table(interactions$Class)
table(sapply(interactions$Class, function(x) strsplit(x, " ")[[1]][2]))
table(identity$Teacher)
pivot_df$Teacher <- gsub("Pat", "Patricia", pivot_df$Teacher)
table(pivot_df$Teacher)
source('~/Dropbox/PAWS-Neal/neal_analysis/data_reshape.R', echo=TRUE)
shiny::runApp('Dropbox/PAWS-Neal/neal_analysis/network_app')
deployApp("~/Documents/tmp/pac_app/")
names(merged_interactions)
subset(merged_interactions, Teacher == "Carrie")
names(merged_interactions)
subset(merged_interactions, Teacher == "Carrie")[,c("PAWSID_S", "PAWSID_R", "Code_B")]
shiny::runApp('Dropbox/PAWS-Neal/neal_analysis/network_app')
shiny::runApp('Dropbox/PAWS-Neal/neal_analysis/network_app')
shiny::runApp('Dropbox/PAWS-Neal/neal_analysis/network_app')
source('~/Dropbox/PAWS-Neal/neal_analysis/examine_network.R', echo=TRUE)
V(g1)$name
plot(g1, layout=layout.fruchterman.reingold,
)
shiny::runApp('Dropbox/PAWS-Neal/neal_analysis/network_app')
source('~/Dropbox/PAWS-Neal/neal_analysis/data_reshape.R', echo=TRUE)
subset(merged_interactions, Teacher == "Carrie")[,c("PAWSID_S", "PAWSID_R", "Code_B")]
shiny::runApp('Dropbox/PAWS-Neal/neal_analysis/network_app')
subset(subset(merged_interactions, Teacher == "Carrie")[,c("PAWSID_S", "PAWSID_R", "Code_B")], PAWSID_S == 90 | PAWSID_R == 90)
subset(subset(merged_interactions, Teacher == "Carrie")[,c("PAWSID_S", "PAWSID_R", "Code_B")], (PAWSID_S == 90 | PAWSID_R == 90) & (PAWSID_S == 221 | PAWSID_R == 221))
source('~/Documents/fbd_viz/rShiny_apps/env_pop/utilities.R', echo=TRUE)
install.packages("RMySQL")
install.packages("RMySQL")
source('~/Documents/fbd_viz/rShiny_apps/env_pop/utilities.R', echo=TRUE)
mortality_output_versions()
library(shiny)
library(shinydashboard)
library(RMySQL)
library(xlsx)
source('~/Documents/fbd_viz/rShiny_apps/env_pop/utilities.R', echo=TRUE)
df <- mortality_results(101,1,28)
mortality_plot(df, "mean_pop")
mortality_plot <- function(df, variable){
ages <- unique(df$age_group_id)
lapply(ages, function(a) single_plot(a, variable, df))
}
test <- mortality_plot(df, "mean_pop")
multiplot(plotlist = test, cols=2)
mortality_plot <- function(df, variable){
ages <- unique(df$age_group_id)
multiplot(plot_list=lapply(ages, function(a)
single_plot(a, variable, df)), cols=2)
}
mortality_plot(df, "mean_pop")
mortality_plot <- function(df, variable){
ages <- unique(df$age_group_id)
multiplot(plot_list=lapply(ages, function(a)
single_plot(a, variable, df)), cols=2)
}
mortality_plot <- function(df, variable){
ages <- unique(df$age_group_id)
multiplot(plotlist=lapply(ages, function(a)
single_plot(a, variable, df)), cols=2)
}
mortality_plot(df, "mean_pop")
shiny::runApp('Documents/fbd_viz/rShiny_apps/env_pop')
shiny::runApp('Documents/fbd_viz/rShiny_apps/env_pop')
shiny::runApp('Documents/fbd_viz/rShiny_apps/env_pop')
shiny::runApp('Documents/fbd_viz/rShiny_apps/env_pop')
df
head(df)
formula("y ~ x")
library(lme4)
?lmer
?dnorm
dnorm(0,log=T)
dnorm(0,log=F)
dnorm(1000,log=F)
dnorm(100,log=F)
dnorm(10,log=F)
dgamma(1000000,0.1, 1,T)
dgamma(1000000,0.1, 1,log=T)
dgamma(1000000,0.1, 10,log=T)
dgamma(.1/10.,0.1, 10,log=T)
dgamma(10.,0.1, 10,log=T)
dnorm(0,log=T)
dnorm(100,log=T)
library("TMB", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
dgamma(10.,0.1, 10,log=T)
dgamma(20.,0.1, 10,log=T)
dgamma(200.,0.1, 10,log=T)
dgamma(200.,0.1, 10,log=T)
dnorm(100,log=T)
dnorm(0,log=T)
dgamma(10.,0.1, 10,log=T)
dgamma(.1.,0.1, 10,log=T)
dgamma(.1,0.1, 10,log=T)
dnorm(0.1,log=T)
dnorm(0.1,log=F)
dnorm(0.1,log=T)
datur <- 1:10
nll <- 0
rm(list=ls())
nll <- 0
datur <- 1:10
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("geoR")
?data
?ca20
library("geoR", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
df <- state_data$Washington$SpatialPolygons@data
set.seed(123)
rm(list=ls())
library(SpatialEpi)
library(spdep)
library(INLA)
library(RColorBrewer)
library(maptools)
library(maps)
library(ggplot2)
library(sp)
library(lattice)
library(surveillance)
library(parallel)
## Get Pennsylvania map file
setwd("~/Documents/Classes/spatial_epi/project/")
load("../homework/hw3/USA_adm2.RData") # From http://gadm.org/
# define the 50 states remove DC
states <- unique(gadm$NAME_1)
states <- as.character(states[!(states %in% c("District of Columbia"))])
# each data unit will be a state with different data
state_data <- lapply(states, function(x) list(name=x))
names(state_data) <- states
# while testing lets only keep three states
state_data <- state_data[c("California", "Washington")]
apply2 <- function(f, new_key, state_data, cores=1){
# apply a function in parallel to an old key of state data and then
# add the newely generated data to the key list
states <- names(state_data)
temp <- mclapply(states, function(x)
f(state_data[[x]]), mc.cores=cores)
names(temp) <- states
for(state in states){
state_data[[state]][[new_key]] <- temp[[state]]
}
state_data
}
state_data <- apply2(function(x) as(gadm[which(gadm$NAME_1==x$name),], "SpatialPolygons"),
"SpatialPolygons", state_data, cores=3)
state_data <- apply2(function(x) poly2adjmat(x$SpatialPolygons),
"adjmat", state_data, cores=3)
distance_matrix <- function(tmat){
loops <- 0
islands <- names(colSums(tmat)[colSums(tmat) == 0])
sans_island <- tmat
sans_island[,] <- TRUE
sans_island[islands,] <- FALSE
sans_island[,islands] <- FALSE
while(sum(tmat[lower.tri(tmat, diag = FALSE) & sans_island] == 0) != 0){
loops <- loops + 1
print(paste0("Running through loop number ", loops))
for(i in 1:(nrow(tmat) - 1)){
for(j in (i+1):(nrow(tmat))){
if(tmat[i,j] == 0){
i_neighbors <- tmat[i,][tmat[i,] != 0]
j_neighbors <- tmat[j,][tmat[j,] != 0]
shared <- intersect(names(i_neighbors), names(j_neighbors))
min_ <- nrow(tmat)
for(s in shared){
distance <- j_neighbors[s] + i_neighbors[s]
if(distance < min_){
min_ <- distance
}
}
if(length(s) > 0 & min_ <= (loops + 1)){
tmat[i,j] <- min_
tmat[j,i] <- min_
}
}
}
}
}
tmat[islands,] <- nrow(tmat) * 3
tmat[,islands] <- nrow(tmat) * 3
tmat[diag(tmat)] <- 0
return (tmat)
}
rmvn <- function(n, mu = 0, V = matrix(1)) {
# http://rstudio-pubs-static.s3.amazonaws.com/9688_a49c681fab974bbca889e3eae9fbb837.html
p <- length(mu)
if (any(is.na(match(dim(V), p))))
stop("Dimension problem!")
D <- chol(V)
t(matrix(rnorm(n * p), ncol = p) %*% D + rep(mu, rep(n, p)))
}
simulate_sre <- function(dist_mat){
N <- nrow(dist_mat)
phi <- 0.38
rmvn(1, rep(0, N), exp(-phi * dist_mat))
}
delta_simulatar <- function(unit){
# Given a spatial polygons data set applies
# a delta to each unit
sp <- unit$SpatialPolygons
dist_mat <- distance_matrix(unit$adjmat)
N <- length(sp) # number of counties in a state unit
sp$ID <- 1:N
datur_od <- sapply(1:100, function(x) rnorm(length(sp), 0, 1))
datur_se <- sapply(1:100, function(x) simulate_sre(dist_mat))
x1 <- sapply(1:100, function(x)rnorm(length(sp)))
x2 <- sapply(1:100, function(x)rnorm(length(sp)))
beta1 <- 2
beta2 <- -3
mean_ <- beta1 * x1 + beta2 * x2
random <- sapply(1:ncol(datur_od), function(x)
rpois(length(datur_od[,x]), exp(datur_od[,x])))
spatial <- sapply(1:ncol(datur_se), function(x)
rpois(length(datur_se[,x]), exp(datur_se[,x])))
both <- sapply(1:ncol(datur_se), function(x)
rpois(length(datur_se[,x]), exp(datur_se[,x] + datur_od[,x])))
random_covs <- sapply(1:ncol(datur_od), function(x)
rpois(length(datur_od[,x]), exp(mean_[,x] + datur_od[,x])))
spatial_covs <- sapply(1:ncol(datur_se), function(x)
rpois(length(datur_se[,x]), exp(mean_[,x] + datur_se[,x])))
both_covs <- sapply(1:ncol(datur_se), function(x)
rpois(length(datur_se[,x]), exp(mean_[,x] + datur_se[,x] + datur_od[,x])))
sp@data[,paste0("over_dispersion", 1:100)] <- datur_od
sp@data[,paste0("spatial_ranom", 1:100)] <- datur_se
sp@data[,paste0("x1", 1:100)] <- x1
sp@data[,paste0("x2", 1:100)] <- x2
sp@data[,paste0("random", 1:100)] <- random
sp@data[,paste0("spatial", 1:100)] <- spatial
sp@data[,paste0("both", 1:100)] <- both
sp@data[,paste0("random_covs", 1:100)] <- random_covs
sp@data[,paste0("spatial_covs", 1:100)] <- spatial_covs
sp@data[,paste0("both_covs", 1:100)] <- both_covs
sp
}
state_data <- apply2(delta_simulatar,"SpatialPolygons", state_data)
df <- state_data$Washington$SpatialPolygons@data
df$ID2 <- rownames(state_data$Washington$adjmat)
summary(glm(spatial_covs100 ~ x1100 + x2100, data=df, family=poisson))
summary(inla(spatial_covs100 ~ x1100 + x2100 +
f(ID2, model="besag", graph=state_data$Washington$adjmat,
param = c(1, 0.68)), data=df, family="poisson"))
summary(inla(spatial_covs100 ~ x1100 + x2100 +
f(ID2, model = "iid", param = c(1, 0.014)),
data=df, family="poisson"))
summary(glm(spatial_covs100 ~ x1100 + x2100, data=df, family=poisson)))
df$ID2 <- as.numeric(rownames(state_data$Washington$adjmat)
}}}
df$ID2 <- as.numeric(rownames(state_data$Washington$adjmat))
summary(inla(spatial_covs100 ~ x1100 + x2100 +
f(ID2, model="besag", graph=state_data$Washington$adjmat,
param = c(1, 0.68)), data=df, family="poisson"))
df$ID <- as.numeric(rownames(state_data$Washington$adjmat))
state_data <- apply2(delta_simulatar,"SpatialPolygons", state_data)
df <- state_data$Washington$SpatialPolygons@data
head(df[,1:5])
summary(inla(spatial_covs100 ~ x1100 + x2100 +
f(ID, model="besag", graph=state_data$Washington$adjmat,
param = c(1, 0.68)), data=df, family="poisson"))
summary(glm(spatial_covs100 ~ x1100 + x2100, data=df, family=poisson)))
summary(glm(spatial_covs100 ~ x1100 + x2100, data=df, family=poisson))
summary(inla(spatial_covs100 ~ x1100 + x2100 +
f(ID, model="besag", graph=state_data$Washington$adjmat,
param = c(1, 0.68)), data=df, family="poisson"))
summary(inla(spatial_covs100 ~ x1100 + x2100 +
f(ID, model = "iid", param = c(1, 0.014)),
data=df, family="poisson"))
summary(df$spatial_ranom100)
rm(list=ls())
load("~/Downloads/USA_adm2.rds")
con <- gzfile("~/Downloads/USA_adm2.rds")
